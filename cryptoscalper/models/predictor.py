# cryptoscalper/models/predictor.py
"""
Module de pr√©diction ML pour le trading en temps r√©el.

Responsabilit√©s :
- Charger le mod√®le XGBoost entra√Æn√©
- Faire des pr√©dictions single et batch
- Calculer la confiance des pr√©dictions
- G√©rer le cache des features pour performance

Usage:
    predictor = MLPredictor.from_file("models/saved/xgb_model_latest.joblib")
    
    # Pr√©diction unique
    result = predictor.predict(feature_set)
    print(f"Proba: {result.probability:.2%}, Confiance: {result.confidence:.2%}")
    
    # Pr√©diction batch
    results = predictor.predict_batch([features1, features2, features3])
"""

from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
import json

import numpy as np
import pandas as pd
import joblib

from cryptoscalper.config.constants import (
    MODELS_DIR,
    MODEL_FILENAME,
    SIGNAL_MIN_PROBABILITY,
    SIGNAL_MIN_CONFIDENCE,
)
from cryptoscalper.data.features import FeatureSet, FeatureEngine, get_feature_names
from cryptoscalper.utils.logger import logger


# ============================================
# CONSTANTES
# ============================================

# Seuils par d√©faut
DEFAULT_MIN_PROBABILITY = SIGNAL_MIN_PROBABILITY  # 0.65
DEFAULT_MIN_CONFIDENCE = SIGNAL_MIN_CONFIDENCE    # 0.55

# Seuil pour consid√©rer une pr√©diction comme "confiante"
# Plus la proba est proche de 0.5, moins on est confiant
CONFIDENCE_NEUTRAL_POINT = 0.5


# ============================================
# DATACLASSES
# ============================================

@dataclass
class PredictionResult:
    """
    R√©sultat d'une pr√©diction ML.
    
    Attributes:
        symbol: Symbole de la paire trad√©e
        probability_up: Probabilit√© de hausse (0-1)
        probability_down: Probabilit√© de baisse (0-1)
        predicted_class: Classe pr√©dite (0 ou 1)
        confidence: Score de confiance (0-1)
        timestamp: Moment de la pr√©diction
        features_used: Nombre de features utilis√©es
        model_version: Version du mod√®le utilis√©
    """
    
    symbol: str
    probability_up: float
    probability_down: float
    predicted_class: int
    confidence: float
    timestamp: datetime = field(default_factory=datetime.now)
    features_used: int = 42
    model_version: str = "unknown"
    
    @property
    def is_bullish(self) -> bool:
        """Indique si la pr√©diction est haussi√®re."""
        return self.predicted_class == 1
    
    @property
    def is_confident(self) -> bool:
        """Indique si la pr√©diction est confiante (> 55%)."""
        return self.confidence >= DEFAULT_MIN_CONFIDENCE
    
    @property
    def is_strong_signal(self) -> bool:
        """Indique si c'est un signal fort (proba >= 65% et confiant)."""
        return self.probability_up >= DEFAULT_MIN_PROBABILITY and self.is_confident
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire."""
        return {
            "symbol": self.symbol,
            "probability_up": self.probability_up,
            "probability_down": self.probability_down,
            "predicted_class": self.predicted_class,
            "confidence": self.confidence,
            "timestamp": self.timestamp.isoformat(),
            "features_used": self.features_used,
            "model_version": self.model_version,
            "is_bullish": self.is_bullish,
            "is_strong_signal": self.is_strong_signal,
        }
    
    def __str__(self) -> str:
        """Repr√©sentation string lisible."""
        direction = "üìà HAUSSE" if self.is_bullish else "üìâ BAISSE"
        strength = "üí™ FORT" if self.is_strong_signal else "‚ö° FAIBLE"
        return (
            f"{self.symbol}: {direction} | "
            f"Proba: {self.probability_up:.1%} | "
            f"Confiance: {self.confidence:.1%} | "
            f"{strength}"
        )


@dataclass
class ModelMetadata:
    """
    M√©tadonn√©es du mod√®le charg√©.
    
    Attributes:
        trained_at: Date d'entra√Ænement
        n_features: Nombre de features attendues
        feature_names: Liste des noms de features
        is_calibrated: Si le mod√®le est calibr√©
        val_auc: AUC sur validation
        model_path: Chemin du fichier mod√®le
    """
    
    trained_at: Optional[datetime] = None
    n_features: int = 42
    feature_names: List[str] = field(default_factory=list)
    is_calibrated: bool = False
    val_auc: float = 0.0
    model_path: str = ""
    
    @classmethod
    def from_json(cls, json_path: Path) -> "ModelMetadata":
        """Charge les m√©tadonn√©es depuis un fichier JSON."""
        if not json_path.exists():
            logger.warning(f"Fichier m√©tadonn√©es introuvable: {json_path}")
            return cls()
        
        try:
            with open(json_path, "r") as f:
                data = json.load(f)
            
            trained_at = None
            if "trained_at" in data:
                trained_at = datetime.fromisoformat(data["trained_at"])
            
            val_auc = 0.0
            if "val_metrics" in data and "roc_auc" in data["val_metrics"]:
                val_auc = data["val_metrics"]["roc_auc"]
            
            return cls(
                trained_at=trained_at,
                n_features=data.get("n_features", 42),
                feature_names=data.get("feature_names", []),
                is_calibrated=data.get("is_calibrated", False),
                val_auc=val_auc,
                model_path=str(json_path.with_suffix(".joblib")),
            )
        except Exception as e:
            logger.error(f"Erreur lecture m√©tadonn√©es: {e}")
            return cls()


# ============================================
# ML PREDICTOR
# ============================================

class MLPredictor:
    """
    Pr√©dicteur ML pour le scalping crypto.
    
    Charge un mod√®le XGBoost entra√Æn√© et fournit des pr√©dictions
    en temps r√©el avec calcul de confiance.
    
    Workflow:
    1. Charger le mod√®le avec from_file()
    2. Passer des features via predict() ou predict_batch()
    3. R√©cup√©rer les r√©sultats avec probabilit√©s et confiance
    
    Exemple:
        predictor = MLPredictor.from_file("models/saved/model.joblib")
        
        # Avec un FeatureSet
        result = predictor.predict(feature_set)
        
        # Avec un dictionnaire de features
        result = predictor.predict_from_dict({"rsi_14": 65.2, ...}, "BTCUSDT")
        
        # Batch
        results = predictor.predict_batch([fs1, fs2, fs3])
    """
    
    def __init__(
        self,
        model: Any,
        metadata: Optional[ModelMetadata] = None,
        feature_names: Optional[List[str]] = None
    ):
        """
        Initialise le predictor avec un mod√®le d√©j√† charg√©.
        
        Args:
            model: Mod√®le sklearn (XGBoost ou calibr√©)
            metadata: M√©tadonn√©es du mod√®le
            feature_names: Liste ordonn√©e des noms de features
        """
        self._model = model
        self._metadata = metadata or ModelMetadata()
        
        # Utiliser les feature names du metadata ou ceux par d√©faut
        if feature_names:
            self._feature_names = feature_names
        elif self._metadata.feature_names:
            self._feature_names = self._metadata.feature_names
        else:
            self._feature_names = get_feature_names()
        
        self._n_features = len(self._feature_names)
        
        logger.info(
            f"ü§ñ MLPredictor initialis√© | "
            f"Features: {self._n_features} | "
            f"Calibr√©: {self._metadata.is_calibrated}"
        )
    
    # =========================================
    # FACTORY METHODS
    # =========================================
    
    @classmethod
    def from_file(
        cls,
        model_path: Optional[Union[str, Path]] = None
    ) -> "MLPredictor":
        """
        Charge le predictor depuis un fichier.
        
        Args:
            model_path: Chemin du fichier .joblib
                       Si None, utilise le chemin par d√©faut
        
        Returns:
            Instance de MLPredictor
            
        Raises:
            FileNotFoundError: Si le fichier n'existe pas
            ValueError: Si le mod√®le est invalide
        """
        if model_path is None:
            model_path = Path(MODELS_DIR) / MODEL_FILENAME
        else:
            model_path = Path(model_path)
        
        if not model_path.exists():
            raise FileNotFoundError(f"Mod√®le introuvable: {model_path}")
        
        logger.info(f"üìÇ Chargement mod√®le: {model_path}")
        
        # Charger le mod√®le
        try:
            model = joblib.load(model_path)
        except Exception as e:
            raise ValueError(f"Erreur chargement mod√®le: {e}") from e
        
        # V√©rifier que le mod√®le a les m√©thodes requises
        if not hasattr(model, "predict_proba"):
            raise ValueError("Le mod√®le doit avoir une m√©thode predict_proba()")
        
        # Charger les m√©tadonn√©es
        meta_path = model_path.with_suffix(".json")
        metadata = ModelMetadata.from_json(meta_path)
        metadata.model_path = str(model_path)
        
        return cls(model, metadata)
    
    # =========================================
    # PROPERTIES
    # =========================================
    
    @property
    def model(self) -> Any:
        """Retourne le mod√®le sous-jacent."""
        return self._model
    
    @property
    def metadata(self) -> ModelMetadata:
        """Retourne les m√©tadonn√©es du mod√®le."""
        return self._metadata
    
    @property
    def feature_names(self) -> List[str]:
        """Retourne la liste des noms de features."""
        return self._feature_names.copy()
    
    @property
    def n_features(self) -> int:
        """Retourne le nombre de features attendues."""
        return self._n_features
    
    @property
    def is_calibrated(self) -> bool:
        """Indique si le mod√®le est calibr√©."""
        return self._metadata.is_calibrated
    
    # =========================================
    # PR√âDICTION SINGLE
    # =========================================
    
    def predict(self, feature_set: FeatureSet) -> PredictionResult:
        """
        Fait une pr√©diction pour une paire.
        
        Args:
            feature_set: Features calcul√©es pour la paire
            
        Returns:
            PredictionResult avec probabilit√© et confiance
        """
        # Pr√©parer les features
        X = self._prepare_features(feature_set.features)
        
        # Pr√©diction
        proba = self._model.predict_proba(X)[0]
        
        # Le mod√®le retourne [proba_classe_0, proba_classe_1]
        prob_down = proba[0]  # Classe 0 = pas de hausse
        prob_up = proba[1]    # Classe 1 = hausse
        
        # Classe pr√©dite (argmax)
        predicted_class = int(np.argmax(proba))
        
        # Calcul de la confiance
        confidence = self._calculate_confidence(prob_up)
        
        return PredictionResult(
            symbol=feature_set.symbol,
            probability_up=float(prob_up),
            probability_down=float(prob_down),
            predicted_class=predicted_class,
            confidence=confidence,
            timestamp=datetime.now(),
            features_used=self._n_features,
            model_version=self._get_model_version(),
        )
    
    def predict_from_dict(
        self,
        features: Dict[str, float],
        symbol: str = "UNKNOWN"
    ) -> PredictionResult:
        """
        Fait une pr√©diction depuis un dictionnaire de features.
        
        Args:
            features: Dictionnaire {nom_feature: valeur}
            symbol: Symbole de la paire
            
        Returns:
            PredictionResult
        """
        # Convertir en FeatureSet
        feature_set = FeatureSet(
            symbol=symbol,
            features=features,
            timestamp=pd.Timestamp.now()
        )
        return self.predict(feature_set)
    
    def predict_from_array(
        self,
        X: np.ndarray,
        symbol: str = "UNKNOWN"
    ) -> PredictionResult:
        """
        Fait une pr√©diction depuis un array numpy.
        
        Args:
            X: Array de shape (n_features,) ou (1, n_features)
            symbol: Symbole de la paire
            
        Returns:
            PredictionResult
        """
        # Reshape si n√©cessaire
        if X.ndim == 1:
            X = X.reshape(1, -1)
        
        # V√©rifier la dimension
        if X.shape[1] != self._n_features:
            raise ValueError(
                f"Attendu {self._n_features} features, re√ßu {X.shape[1]}"
            )
        
        # Pr√©diction
        proba = self._model.predict_proba(X)[0]
        prob_down, prob_up = proba[0], proba[1]
        predicted_class = int(np.argmax(proba))
        confidence = self._calculate_confidence(prob_up)
        
        return PredictionResult(
            symbol=symbol,
            probability_up=float(prob_up),
            probability_down=float(prob_down),
            predicted_class=predicted_class,
            confidence=confidence,
            timestamp=datetime.now(),
            features_used=self._n_features,
            model_version=self._get_model_version(),
        )
    
    # =========================================
    # PR√âDICTION BATCH
    # =========================================
    
    def predict_batch(
        self,
        feature_sets: List[FeatureSet]
    ) -> List[PredictionResult]:
        """
        Fait des pr√©dictions pour plusieurs paires.
        
        Plus efficace que d'appeler predict() en boucle car
        le mod√®le peut traiter un batch en une seule fois.
        
        Args:
            feature_sets: Liste de FeatureSet
            
        Returns:
            Liste de PredictionResult dans le m√™me ordre
        """
        if not feature_sets:
            return []
        
        # Pr√©parer la matrice de features
        symbols = []
        X_list = []
        
        for fs in feature_sets:
            symbols.append(fs.symbol)
            X_list.append(self._prepare_features(fs.features).flatten())
        
        X = np.array(X_list)
        
        # Pr√©diction batch
        probas = self._model.predict_proba(X)
        
        # Construire les r√©sultats
        results = []
        timestamp = datetime.now()
        model_version = self._get_model_version()
        
        for i, (symbol, proba) in enumerate(zip(symbols, probas)):
            prob_down, prob_up = proba[0], proba[1]
            predicted_class = int(np.argmax(proba))
            confidence = self._calculate_confidence(prob_up)
            
            results.append(PredictionResult(
                symbol=symbol,
                probability_up=float(prob_up),
                probability_down=float(prob_down),
                predicted_class=predicted_class,
                confidence=confidence,
                timestamp=timestamp,
                features_used=self._n_features,
                model_version=model_version,
            ))
        
        return results
    
    def predict_batch_dataframe(
        self,
        df: pd.DataFrame,
        symbol_column: Optional[str] = None
    ) -> List[PredictionResult]:
        """
        Fait des pr√©dictions depuis un DataFrame.
        
        Args:
            df: DataFrame avec les features en colonnes
            symbol_column: Nom de la colonne symbole (optionnel)
            
        Returns:
            Liste de PredictionResult
        """
        # Extraire les features
        feature_cols = [c for c in self._feature_names if c in df.columns]
        
        if len(feature_cols) != self._n_features:
            missing = set(self._feature_names) - set(feature_cols)
            raise ValueError(f"Features manquantes: {missing}")
        
        X = df[feature_cols].values
        
        # Symboles
        if symbol_column and symbol_column in df.columns:
            symbols = df[symbol_column].tolist()
        else:
            symbols = [f"ROW_{i}" for i in range(len(df))]
        
        # Pr√©dictions
        probas = self._model.predict_proba(X)
        
        results = []
        timestamp = datetime.now()
        model_version = self._get_model_version()
        
        for symbol, proba in zip(symbols, probas):
            prob_down, prob_up = proba[0], proba[1]
            predicted_class = int(np.argmax(proba))
            confidence = self._calculate_confidence(prob_up)
            
            results.append(PredictionResult(
                symbol=symbol,
                probability_up=float(prob_up),
                probability_down=float(prob_down),
                predicted_class=predicted_class,
                confidence=confidence,
                timestamp=timestamp,
                features_used=self._n_features,
                model_version=model_version,
            ))
        
        return results
    
    # =========================================
    # M√âTHODES PRIV√âES
    # =========================================
    
    def _prepare_features(self, features: Dict[str, float]) -> np.ndarray:
        """
        Pr√©pare les features pour le mod√®le.
        
        Assure que les features sont dans le bon ordre et remplace
        les NaN par 0 (ou une valeur par d√©faut).
        
        Args:
            features: Dictionnaire des features
            
        Returns:
            Array numpy de shape (1, n_features)
        """
        # Extraire les valeurs dans l'ordre correct
        values = []
        for name in self._feature_names:
            value = features.get(name, np.nan)
            # Remplacer NaN par 0 (le mod√®le g√®re mal les NaN)
            if pd.isna(value):
                value = 0.0
            values.append(value)
        
        return np.array(values).reshape(1, -1)
    
    def _calculate_confidence(self, probability_up: float) -> float:
        """
        Calcule un score de confiance bas√© sur la probabilit√©.
        
        La confiance est maximale quand la proba est proche de 0 ou 1,
        et minimale quand elle est proche de 0.5 (incertitude).
        
        Formule: confidence = 2 * |probability - 0.5|
        
        Exemples:
        - probability = 0.5 ‚Üí confidence = 0 (incertain)
        - probability = 0.7 ‚Üí confidence = 0.4
        - probability = 0.8 ‚Üí confidence = 0.6
        - probability = 0.9 ‚Üí confidence = 0.8
        - probability = 1.0 ‚Üí confidence = 1.0 (tr√®s confiant)
        
        Args:
            probability_up: Probabilit√© de hausse (0-1)
            
        Returns:
            Score de confiance (0-1)
        """
        return 2 * abs(probability_up - CONFIDENCE_NEUTRAL_POINT)
    
    def _get_model_version(self) -> str:
        """Retourne une version du mod√®le pour tracking."""
        if self._metadata.trained_at:
            return self._metadata.trained_at.strftime("%Y%m%d_%H%M%S")
        return "unknown"
    
    # =========================================
    # UTILITAIRES
    # =========================================
    
    def get_top_predictions(
        self,
        predictions: List[PredictionResult],
        n: int = 5,
        min_probability: float = DEFAULT_MIN_PROBABILITY,
        min_confidence: float = DEFAULT_MIN_CONFIDENCE
    ) -> List[PredictionResult]:
        """
        Filtre et trie les meilleures pr√©dictions.
        
        Args:
            predictions: Liste de pr√©dictions
            n: Nombre max de r√©sultats
            min_probability: Seuil de probabilit√© minimum
            min_confidence: Seuil de confiance minimum
            
        Returns:
            Top N pr√©dictions tri√©es par probabilit√© d√©croissante
        """
        # Filtrer
        filtered = [
            p for p in predictions
            if p.probability_up >= min_probability
            and p.confidence >= min_confidence
            and p.is_bullish
        ]
        
        # Trier par probabilit√© d√©croissante
        sorted_preds = sorted(
            filtered,
            key=lambda p: p.probability_up,
            reverse=True
        )
        
        return sorted_preds[:n]
    
    def summary(self) -> str:
        """Retourne un r√©sum√© du predictor."""
        return (
            f"ü§ñ MLPredictor\n"
            f"{'=' * 40}\n"
            f"üìÇ Mod√®le: {self._metadata.model_path}\n"
            f"üìÖ Entra√Æn√©: {self._metadata.trained_at}\n"
            f"üî¢ Features: {self._n_features}\n"
            f"üìê Calibr√©: {'Oui' if self._metadata.is_calibrated else 'Non'}\n"
            f"üìä AUC validation: {self._metadata.val_auc:.4f}"
        )


# ============================================
# FONCTIONS UTILITAIRES
# ============================================

def load_predictor(model_path: Optional[Union[str, Path]] = None) -> MLPredictor:
    """
    Fonction utilitaire pour charger rapidement un predictor.
    
    Args:
        model_path: Chemin du mod√®le (d√©faut si None)
        
    Returns:
        MLPredictor charg√©
    """
    return MLPredictor.from_file(model_path)


def predict_single(
    features: Dict[str, float],
    symbol: str,
    model_path: Optional[Union[str, Path]] = None
) -> PredictionResult:
    """
    Fonction utilitaire pour une pr√©diction rapide.
    
    Note: Charge le mod√®le √† chaque appel, donc inefficace pour
    des pr√©dictions r√©p√©t√©es. Utiliser MLPredictor directement
    pour de meilleures performances.
    
    Args:
        features: Dictionnaire des features
        symbol: Symbole de la paire
        model_path: Chemin du mod√®le
        
    Returns:
        PredictionResult
    """
    predictor = load_predictor(model_path)
    return predictor.predict_from_dict(features, symbol)